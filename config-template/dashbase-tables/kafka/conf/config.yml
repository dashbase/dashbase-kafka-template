dashbase:
  baseDir: /data/index
  readerCacheSize: 10000

  firehose:
      type: kafka_10
      params:
          hosts: ${KAFKA_BROKER_HOST}
          groupId: ${KAFKA_GROUPID}
          topic: ${KAFKA_TOPIC}
          partitions: "0"
# NOTE: the following setting does not seem to make a difference.
#          kafkaProps:
#            max.partition.fetch.bytes: 4048576
#            receive.buffer.bytes: 2455360

  cluster:
    name: kafka
    url: ${ZOOKEEPER_URL}

  indexer:
    maxDocsPerSegment: 1000000
    # numIndexingThreads: 3
    #maxNumConcurrentBuilding: 3
    maxIndexingDelayInSec: 15

  retention:
    numDays: 7

  parser:
    type: json
    params:
      pattern:
        timeFormat: now
        schema:
          - name: host
            type: meta
          - name: request
            type: text
          - name: response
            type: meta
          - name: bytesSent
            type: numeric
          - name: error
            type: meta
          - name: msg
            type: text
          - name: level
            type: meta
          - name: agent
            type: text
server:
  applicationConnectors:
    - type: http
      port: ${PORT}
  applicationContextPath: /
  adminContextPath: /admin
  adminConnectors:
      - type: http
        port: ${ADMINPORT}

metrics:
  reporters:
    - type: dashbase
      url: ${MONITOR_URL}
      includes:
        - ^jvm.*$
        - ^dashbase.*$
      useRegexFilters: true
      frequency: 5 seconds

logging:
  level: INFO
  appenders:
      - type: file
        currentLogFilename: ../logs/dashbase-kafka.log
        archive: true
        archivedLogFilenamePattern: ../logs/dashbase-kafka-%d.log
        archivedFileCount: 9
        timeZone: UTC
      - type: dashbase
        url: ${MONITOR_URL}
        timeZone: UTC
